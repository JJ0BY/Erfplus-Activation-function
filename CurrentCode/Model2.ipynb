{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time as t \n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#residual block \n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, actFunc=nn.ReLU, stride = 1, downsample = False):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        #Sequential layer 1 \n",
    "        self.FC1 = nn.Sequential(\n",
    "                        nn.BatchNorm1d(in_channels),\n",
    "                        nn.Linear(in_channels, out_channels),\n",
    "                        actFunc())\n",
    "        \n",
    "        #Sequential layer 1 \n",
    "        self.FC2 = nn.Sequential(\n",
    "                        nn.BatchNorm1d(out_channels),\n",
    "                        nn.Linear(out_channels, out_channels)\n",
    "                        )\n",
    "        \n",
    "        #downsample is never used \n",
    "        self.downsample = downsample\n",
    "        self.actFunc1 = actFunc()\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    #Resnet like model with fully connected layers rather than convolutional layers \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.FC1(x)\n",
    "        out = self.FC2(out)\n",
    "        #out = self.actFunc(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.actFunc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, img_input_dim = 64, actFunc=nn.ReLU, num_classes = 10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        \n",
    "        #main activation function \n",
    "        self.actFunc = actFunc\n",
    "        \n",
    "        #layers \n",
    "        self.encoder = nn.Linear(img_input_dim*img_input_dim, self.inplanes)\n",
    "        self.input_actFunc = actFunc()\n",
    "        self.hid_layers = self._make_layer(block, self.inplanes, layers, stride = 1)\n",
    "        self.decoder = nn.Linear(self.inplanes, num_classes)\n",
    "        \n",
    "        #Softmax function to decide what the output image should be \n",
    "        self.output_actFunc = nn.Softmax(dim=1)\n",
    "        #Loss function \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    #Make layer function\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = False\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(planes),\n",
    "            )\n",
    "        downsample = False\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, self.actFunc, stride, downsample))\n",
    "        self.inplanes = planes\n",
    "        #Add each block \n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, self.actFunc))\n",
    "\n",
    "        #Return sequential layer \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    #Forward function \n",
    "    def forward(self, x):\n",
    "        #Encoder \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.encoder(x)\n",
    "        x = self.input_actFunc(x)\n",
    "        \n",
    "        #Hidden layers \n",
    "        x = self.hid_layers(x)\n",
    "        \n",
    "        #Decoder \n",
    "        x = self.decoder(x)\n",
    "        x = self.output_actFunc(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    #Evaluate the model \n",
    "    def evaluate(self, val_loader):\n",
    "        \"\"\"Evaluate the model's performance on the validation set\"\"\"\n",
    "        outputs = [self.validation_step(batch) for batch in val_loader]\n",
    "        return self.validation_epoch_end(outputs)\n",
    "\n",
    "    #training and testing model \n",
    "    def fit(self, epochs, lr, mo, train_loader, val_loader, opt_func=torch.optim.SGD, print_statement=True):\n",
    "        \"\"\"Train the model using gradient descent\"\"\"\n",
    "        history = []\n",
    "        #Set the optimizer function \n",
    "        optimizer = opt_func(self.parameters(), lr, mo)\n",
    "        \n",
    "        #For each epoch do the following \n",
    "        for epoch in range(epochs):\n",
    "            t0 = t.time() \n",
    "            # Training Phase (Set training mode)\n",
    "            self.train() \n",
    "            #For each batch optimize the model \n",
    "            for batch in train_loader:\n",
    "                loss = self.training_step(batch)\n",
    "                loss.backward()\n",
    "                #loss.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "            # Validation phase (Set evaluation mode to avoid calculating gradients)\n",
    "            self.eval()\n",
    "            with torch.inference_mode():\n",
    "                result = self.evaluate(val_loader)\n",
    "            result['epoch_time'] = t.time() - t0 \n",
    "            \n",
    "            #print the results \n",
    "            if print_statement:\n",
    "                self.epoch_end(epoch, result)\n",
    "            history.append(result)\n",
    "        if print_statement:\n",
    "            print('-----------------------------------------------------')\n",
    "        return history\n",
    "    \n",
    "    #Find the loss for training \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self.forward(images)                  # Generate predictions\n",
    "        loss = self.criterion(out, labels) # Calculate loss\n",
    "        return loss\n",
    "\n",
    "    #Find the accuracy of given dataset \n",
    "    def accuracy(self, outputs, labels):\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "    \n",
    "    #Find the accuracy for validation \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self.forward(images)                 # Generate predictions\n",
    "        loss = self.criterion(out, labels)         # Calculate loss\n",
    "        acc = self.accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "        \n",
    "    #plot the validation results \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        \n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    #Print statement for final epoch result \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}] val_loss: {:.4f}, val_acc: {:.4f}, time: {:.4f} s\".format(epoch, result['val_loss'], result['val_acc'], result['epoch_time']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "S4_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
